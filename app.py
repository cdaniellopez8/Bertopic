import streamlit as st
import pandas as pd
from bertopic import BERTopic
from bertopic.representation import OpenAI, KeyBERTInspired
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
import openai
import os
import plotly.express as px
import nltk

# Descargar stopwords de NLTK si no est√°n presentes
try:
    nltk.data.find('corpora/stopwords')
except: # Capturamos cualquier excepci√≥n, incluyendo la de recurso no encontrado
    st.info("Descargando el recurso 'stopwords' de NLTK por primera vez. Esto solo sucede una vez.")
    nltk.download('stopwords')

# --- CONFIGURACI√ìN Y CACH√â DE RECURSOS ---

# T√≠tulo y Configuraci√≥n Inicial
st.set_page_config(layout="wide", page_title="ShakiraGPT: An√°lisis de T√≥picos")
st.title("üé§ ShakiraGPT: La Evoluci√≥n Tem√°tica de una Loba üê∫")
st.markdown("---")

# üîë Carga de la Clave API de OpenAI
openai_api_key = None
try:
    openai_api_key = st.secrets["openai"]["api_key"]
except (KeyError, AttributeError):
    openai_api_key = os.environ.get("OPENAI_API_KEY")

if not openai_api_key:
    st.sidebar.error("‚ö†Ô∏è La clave API de OpenAI no est√° configurada. El Paso 4 estar√° deshabilitado.")

# 1. Cargar y Preprocesar los datos (Usando cach√© de datos)
@st.cache_data
def load_data(file_path):
    """Carga el Excel y hace una limpieza b√°sica."""
    try:
        df = pd.read_excel(file_path)
    except FileNotFoundError:
        st.error(f"Error: No se encontr√≥ el archivo '{file_path}'. Aseg√∫rate de que est√© en la carpeta del proyecto.")
        st.stop()
        
    df = df.dropna(subset=['lyrics', 'song', 'year'])
    df['lyrics'] = df['lyrics'].astype(str)
    df['year'] = pd.to_numeric(df['year'], errors='coerce').fillna(0).astype(int)
    return df.sort_values(by='year')


# 2. Entrenar o cargar el modelo BERTopic (Usando cach√© de recursos)
@st.cache_resource
def train_bertopic(docs, use_llm_representation=False):
    """Inicializa y entrena el modelo BERTopic."""
    
    # --- Definici√≥n de Stopwords para el preprocesamiento (¬°Mejora 3!)
    spanish_stopwords = stopwords.words('spanish')
    vectorizer_model = CountVectorizer(stop_words=spanish_stopwords, min_df=2)

    representation_model = None
    
    # 4. Configurar el Modelo de Representaci√≥n (Paso Clave)
    if use_llm_representation and openai_api_key:
        try:
            client = openai.OpenAI(api_key=openai_api_key)
            
            prompt = """
            Genera un t√≠tulo corto y conciso (m√°ximo 6 palabras) para este t√≥pico. 
            El t√≥pico contiene letras de canciones. El t√≠tulo debe ser profesional y capturar la esencia del tema.
            """
            
            representation_model = OpenAI(client, 
                                          model="gpt-4o-mini", 
                                          chat=True,
                                          prompt=prompt,
                                          delay_in_seconds=5)
        except Exception as e:
            st.warning(f"Error al inicializar OpenAI: {e}. Se usar√° KeyBERT.")
            representation_model = None
    
    # Si no se usa LLM, usamos KeyBERT como representaci√≥n secundaria m√°s legible
    if not representation_model:
        representation_model = KeyBERTInspired()
            
    # Inicializaci√≥n de BERTopic
    topic_model = BERTopic(
        language="multilingual", 
        calculate_probabilities=True,
        verbose=False,
        representation_model=representation_model,
        # Se a√±ade el vectorizador con las stopwords aqu√≠
        vectorizer_model=vectorizer_model 
    )
    
    # Entrenamiento
    with st.spinner("‚ú® Creando Embeddings y Descubriendo T√≥picos... ¬°Esto puede tardar unos minutos! ‚è≥"):
        topics, probs = topic_model.fit_transform(docs)
    
    return topic_model, topics, probs

# --- INTERFAZ DE USUARIO Y EJECUCI√ìN ---

# Cargar los datos
FILE_PATH = 'shak.xlsx'
df_shakira = load_data(FILE_PATH)
docs = df_shakira['lyrics'].tolist()

# Sidebar para la configuraci√≥n pedag√≥gica (Paso 4)
st.sidebar.header("Opciones de Modelado")
use_llm = st.sidebar.toggle(
    "Usar GPT-4o-mini para nombres de T√≥picos (Paso 4)", 
    value=False,
    disabled=not openai_api_key
)

# Entrenar el modelo
topic_model, topics, probs = train_bertopic(docs, use_llm_representation=use_llm)
df_shakira['topic'] = topics

# Filtrar outliers (-1) para las visualizaciones de t√≥picos principales
df_topics_info = topic_model.get_topic_info()
df_topics = df_topics_info[df_topics_info['Topic'] != -1]
df_topics = df_topics.rename(columns={
    'Name': 'Nombre del T√≥pico (Final)', 
    'Count': 'Canciones', 
    'Representation': 'Palabras Clave (c-TF-IDF)'
})

# --------------------------------------------------------------------------------------
# ‚û°Ô∏è ORDEN PEDAG√ìGICO CORREGIDO
# --------------------------------------------------------------------------------------

## 1Ô∏è‚É£ Exploraci√≥n de Datos
st.header("1Ô∏è‚É£ Exploraci√≥n de Datos: La Materia Prima")
st.write(f"Corpus cargado: **{len(df_shakira)}** canciones de Shakira.")
st.dataframe(df_shakira[['song', 'year', 'lyrics']].head(), use_container_width=True)

st.markdown("---")

## 2Ô∏è‚É£ Incrustaci√≥n y Reducci√≥n de Dimensionalidad (BERT + UMAP)
st.header("2Ô∏è‚É£ Incrustaci√≥n (BERT) y Reducci√≥n (UMAP)")
st.markdown("""
El primer paso de BERTopic es convertir las letras en **vectores** (Embeddings) usando BERT para capturar su significado. 
Luego, **UMAP** reduce esos vectores de alta dimensi√≥n a 2D para que podamos visualizarlos.
""")
st.markdown("Cada punto en el gr√°fico es una canci√≥n. La **proximidad** indica similitud sem√°ntica de las letras.")

# Generar y mostrar el gr√°fico de documentos (¬°Mejora 2 - UMAP!)
# Se necesita obtener los embeddings y el UMAP_model para visualizar
if hasattr(topic_model, 'umap_model') and topic_model.umap_model is not None:
    try:
        # Forzar la generaci√≥n si no existe (aunque fit_transform deber√≠a haberlo hecho)
        embeddings = topic_model._extract_embeddings(docs)
        reduced_embeddings = topic_model.umap_model.transform(embeddings)
        
        # Usar la funci√≥n visualize_documents de BERTopic
        fig_docs = topic_model.visualize_documents(docs, custom_labels=True, title="Mapa de T√≥picos (UMAP)")
        st.plotly_chart(fig_docs, use_container_width=True)
    except Exception as e:
        st.error(f"Error al generar la visualizaci√≥n UMAP: {e}. Puede deberse a pocos datos o problemas de clustering.")
else:
     st.warning("El modelo UMAP no est√° disponible, el entrenamiento pudo fallar o se requieren m√°s datos.")
    
st.markdown("---")

## 3Ô∏è‚É£ Agrupaci√≥n (HDBSCAN) y Generaci√≥n Inicial de T√≥picos (c-TF-IDF)
st.header("3Ô∏è‚É£ Agrupaci√≥n (HDBSCAN) y T√≥picos Base (c-TF-IDF)")
st.markdown("""
**HDBSCAN** agrupa los puntos cercanos en el espacio UMAP para formar *clusters* de canciones.
**c-TF-IDF** genera las palabras clave para cada *cluster* (t√≥pico), ignorando las *stopwords* comunes en espa√±ol.
""")

st.subheader("Palabras Clave por T√≥pico (¬°Mejora 3 - Keywords visibles!)")
st.info("La columna 'Palabras Clave' muestra la representaci√≥n inicial, **sin incluir palabras comunes como 'el', 'la', 'que'**.")
st.dataframe(
    df_topics[['Topic', 'Canciones', 'Palabras Clave (c-TF-IDF)']], 
    use_container_width=True
)

st.subheader("Visualizaci√≥n de Palabras Clave")
fig_bar = topic_model.visualize_barchart(top_n_topics=10, n_words=8, custom_labels=True)
st.plotly_chart(fig_bar, use_container_width=True)

st.markdown("---")

## 4Ô∏è‚É£ Mejora de la Representaci√≥n con LLMs (Paso Clave)
st.header("4Ô∏è‚É£ Mejora de la Representaci√≥n con LLMs (Paso Opcional de Calidad)")

if use_llm:
    st.success("‚úÖ ¬°GPT-4o-mini ha generado nombres coherentes para los t√≥picos!")
    
    st.subheader("Etiquetas de T√≥picos Mejoradas (GPT-4o-mini)")
    st.dataframe(
        df_topics[['Topic', 'Nombre del T√≥pico (Final)', 'Canciones', 'Palabras Clave (c-TF-IDF)']], 
        use_container_width=True
    )
    
    st.markdown("---")
    st.subheader("Ejemplo Pedag√≥gico: Comparaci√≥n de Etiquetas")
    
    # Mostrar la diferencia en el primer t√≥pico
    first_topic_id = df_topics['Topic'].iloc[0]
    
    # Nota: BERTopic sobrescribe 'Name'. Para comparaci√≥n, se usa la representaci√≥n c-TF-IDF
    c_tfidf_words = ", ".join([word[0] for word in topic_model.get_topic(first_topic_id)])
    llm_name = df_topics[df_topics['Topic'] == first_topic_id]['Nombre del T√≥pico (Final)'].iloc[0]

    st.markdown(f"**T√≥pico m√°s frecuente (T√≥pico {first_topic_id}):**")
    st.code(f"Palabras Clave (c-TF-IDF): {c_tfidf_words}", language='text')
    st.code(f"Nombre Generado por LLM: {llm_name}", language='text')
    st.markdown("Esto demuestra c√≥mo un LLM transforma una lista de palabras en un concepto legible.")

    
else:
    st.info("üí° Activa el interruptor en la barra lateral para ver c√≥mo GPT-4o-mini mejora las etiquetas de t√≥picos (se requiere API Key).")
    st.subheader("Etiquetas por Defecto (KeyBERT)")
    st.dataframe(
        df_topics[['Topic', 'Nombre del T√≥pico (Final)', 'Canciones', 'Palabras Clave (c-TF-IDF)']], 
        use_container_width=True
    )

st.markdown("---")

## 5Ô∏è‚É£ Conclusiones y An√°lisis a Trav√©s del Tiempo
st.header("5Ô∏è‚É£ An√°lisis Final: T√≥picos a Trav√©s del Tiempo")

st.subheader("Evoluci√≥n de la Prominencia Tem√°tica")
st.markdown("Este gr√°fico muestra c√≥mo la importancia de cada t√≥pico ha evolucionado a lo largo de la carrera de Shakira.")

try:
    df_shakira['year'] = df_shakira['year'].astype(int)
    topics_over_time = topic_model.topics_over_time(docs, df_shakira['year'])
    fig_time = topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=10, custom_labels=True)
    st.plotly_chart(fig_time, use_container_width=True)
except Exception as e:
    st.warning(f"Error al generar el gr√°fico temporal: {e}. Aseg√∫rate de que tienes datos de a√±os variados.")


st.markdown("---")

st.header("üîç Exploraci√≥n Detallada de Canciones")

selected_topic_id = st.selectbox(
    "Selecciona un T√≥pico para ver sus Canciones:",
    options=df_topics['Topic'].tolist(),
    format_func=lambda x: f"T√≥pico {x}: {df_topics[df_topics['Topic'] == x]['Nombre del T√≥pico (Final)'].iloc[0]}"
)

songs_in_topic = df_shakira[df_shakira['topic'] == selected_topic_id]

if not songs_in_topic.empty:
    st.subheader(f"Canciones para el T√≥pico {selected_topic_id}")
    st.dataframe(songs_in_topic[['year', 'song', 'lyrics']], use_container_width=True)
else:
    st.info("No hay canciones para este t√≥pico.")

st.caption("¬°Gracias por explorar la evoluci√≥n de los t√≥picos en la discograf√≠a de Shakira!")


